{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuyNYAMSI/exemple_repos/blob/main/Compl%C3%A9ments_couches_denses.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljUdbmTomESG"
      },
      "source": [
        "<center><img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/logo_datascientest.png\" style=\"height:150px;center\"></center>\n",
        "\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "<center><h1>Deep-Learning - Modules complémentaires</h1></center>\n",
        "<center><h2>Compléments sur le dataset MNIST</h2></center>\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "\n",
        "\n",
        "Le but de cet exercice est d'approfondir nos connaissances sur l'entraînement d'un modèle en deep learning.\n",
        "\n",
        " Nous allons travailler avec la base de données **```MNIST```**. Cette base contient des images de chiffres manuscrits que nous tenterons de classifier.\n",
        "\n",
        "> Nous aborderons les points suivants : \n",
        ">> I - [Préparation du dataset](#preparation)\n",
        ">>\n",
        ">>\n",
        ">> II - [Influence de la taille des batchs](#batch_size)\n",
        ">>> A - [Pour nombre d'epoch fixé](#fixed_epochs)\n",
        ">>>\n",
        ">>>\n",
        ">>> B - [Pour un nombre d'itérations fixé](#fixed_iterations)\n",
        ">>\n",
        ">>\n",
        ">> III - [Illustration du surentraînement](#overfitting)\n",
        ">>\n",
        ">>\n",
        ">> IV - [Influence du nombre d'images dans le jeu d'entraînement](#train_size)\n",
        ">>\n",
        ">>\n",
        ">> V - [Influence de l'architecture du réseau de neurones](#architecture)\n",
        ">>> A - [Architecture très basique VS architecture plus complexes](#dense)\n",
        ">>>\n",
        ">>>\n",
        ">>> B - [Introduction aux réseaux de neurones convolutionnels](#CNN)\n",
        "\n",
        "- (a) Exécuter la cellule ci-dessous pour importer les modules nécessaires à l'exercice ainsi que le dataset ```MNIST```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXxzH7T_4wS6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "\n",
        "import time\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xQq2gwazUE6"
      },
      "source": [
        "- (b) Afficher, dans une grille de figures, 6 images tirées aléatoirement de l'échantillon ```X_train```, avec en titre les labels correspondants de ```y_train```.\n",
        "> - Cet affichage a déjà été fait dans le premier notebook du cours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcgJGKdahzly"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yxBTeHulVUw"
      },
      "source": [
        "# <a name=\"preparation\"></a> I - Préparation du dataset\n",
        "\n",
        "- (a) Changer la forme des images de ```X_train``` et de ```X_test``` en des vecteurs de tailles **28*28** à l'aide de la méthode ```reshape```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A1TyDaKh0wx"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOs5qIx90e_e"
      },
      "source": [
        "- (b) Pour une meilleure performance du modèle, réduire les pixels des données ```X_train``` et ```X_test``` afin qu'ils soient compris entre 0 et 1. \n",
        "> - Diviser **l'ensemble de l'échantillon** par 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZGbeJ8Eh19b"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDQ0TQH705aV"
      },
      "source": [
        "- (c) Transformer les labels de ```y_train``` et ```y_test``` en vecteurs catégoriels binaires (one hot) grâce à la fonction to_categorical du sous-module ```np_utils``` de ```keras```.\n",
        "\n",
        "- (d) Extraire dans des variables appelées respectivement ```num_pixels``` et ```num_classes``` le nombre de colonnes (pixels) de ```X_train``` et le nombre de colonnes (classes) de ```y_test```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wexfGNnsh28n"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlTiqhRqif2n"
      },
      "source": [
        "# <a name=\"batch_size\"></a> II - Influence de la taille des batchs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmTA0PJj1lPJ"
      },
      "source": [
        "## <a name=\"fixed_epochs\"></a> A - Nombre fixe d'epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R55E4aSya7v_"
      },
      "source": [
        "- (a) Définir une liste ```batch_sizes``` contenant les valeurs ```[1, 20, 50, 200, 500, 2000, 4000]```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q47PElhah42O"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvcHdhpIbLOE"
      },
      "source": [
        "Nous allons utiliser le modèle suivant :\n",
        "\n",
        "\n",
        "```\n",
        "  model = Sequential()\n",
        "  model.add(Dense(units = 20, input_dim = num_pixels, kernel_initializer ='normal', activation ='tanh'))             \n",
        "  model.add(Dense(units = num_classes, kernel_initializer ='normal', activation ='softmax'))\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "- (b) Pour chaque taille de batch défini dans ```batch_sizes```, définir et entraîner le modèle sur les données ```X_train``` et ```y_train``` grâce à la méthode ```fit``` :\n",
        ">  - L'entraînement devra se faire sur 5 epochs (paramètre ```epochs```).\n",
        ">\n",
        ">  - La performance du modèle devra être évaluée sur un échantillon de validation contenant 20% des données (paramètre ```validation_split```).\n",
        ">\n",
        ">  - La sortie des entraînements devra être stockée dans une liste nommée ```training_histories_fixed_epoch```.\n",
        "\n",
        "- (c) Stocker dans une liste ```times_fixed_epoch``` la durée de chaque entraînement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YKKk6bDh6fv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeBgSXysjE82"
      },
      "source": [
        "- (d) Tracer sur un même graphe l'évolution de la précision d'entraînement en fonction de l'epoch pour chaque taille de batch.\n",
        "\n",
        "- (e) Sur un second graphe, tracer le temps d'entraînement du modèle pour chaque taille de batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTsfNFhYh7m9"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w69hPP04idZO"
      },
      "source": [
        "## <a name=\"fixed_iterations\"></a> B - Nombre fixe d'itérations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh5zwPLoj_bh"
      },
      "source": [
        "- (f) Définir une liste ```batch_sizes_2``` contenant les valeurs ```[20, 50, 200, 500, 2000, 4000]```.\n",
        "\n",
        "- (g) Définir une liste ```epochs``` contenant les valeurs de ```batch_size_2``` divisées par 5.\n",
        ">  - Cela permettra d'entrainer le modèle sur un nombre fixe d'itération plutôt qu'un nombre fixe d'epochs.\n",
        ">\n",
        ">  - Attention à ce que les valeurs de ```epochs``` soient bien des valeurs entières."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5T2VzEyh9EO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7QHYcGlj5Fa"
      },
      "source": [
        "- (h) Pour chaque taille de batch défini dans ```batch_sizes```, définir et entraîner le modèle sur les données ```X_train``` et ```y_train``` grâce à la méthode ```fit``` :\n",
        ">  - L'entraînement devra se faire avec les éléments de la liste ```epoch``` (paramètre ```epochs```).\n",
        ">\n",
        ">  - La perfomance du modèle devra être évaluée sur un échantillon de validation contenant 20% des données (paramètre ```validation_split```).\n",
        ">\n",
        ">  - La sortie des entraînements devra être stockée dans une liste nommée ```training_histories_fixed_iterations```.\n",
        "\n",
        "- (i) Stocker dans une liste ```times_fixed_iterations``` la durée de chaque entraînement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EPZJKj9h94D"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh-vtuCZn6Av"
      },
      "source": [
        "- (j) Tracer sur un même graphe l'évolution de la précision d'entraînement en fonction des itérations pour chaque taille de batch.\n",
        "\n",
        "- (k) Sur un second graphe, tracer le temps d'entraînement du modèle pour chaque taille de batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK7Wt_nNiEFT"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh1Uy7s6oCUh"
      },
      "source": [
        "On remarque que plus on entraîne notre modèle, plus la précision d'entraînement augmente. On peut alors penser que plus on entraîne notre modèle, meilleure sera la prédiction.\n",
        "\n",
        "Ceci est très loin de la vérité. C'est même un des problèmes les plus classiques en deep learning, qu'on appelle **le surentraînement** (ou **overfitting**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59323HlKintj"
      },
      "source": [
        "# <a name=\"overfitting\"></a> III - Illustration du surentraînement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOd24PFQp0j1"
      },
      "source": [
        "- (a) Instancier le même modèle que lors de la partie précédente.\n",
        "\n",
        "- (b) Entraîner le modèle sur les données ```X_train``` et ```y_train``` grâce à la méthode ```fit``` :\n",
        ">  - L'entraînement devra se faire sur **100** epochs (paramètre ```epochs```).\n",
        ">\n",
        ">  - Les batchs devront avoir une taille de 20 (paramètre ```batch_size```)\n",
        ">\n",
        ">  - La perfomance du modèle devra être évaluée sur un échantillon de validation contenant 20% des données (paramètre ```validation_split```).\n",
        ">\n",
        ">  - La sortie de l'entraînement devra être stockée dans une variable nommée ```training_history```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hp5ZlPUiGHL"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fUeK0OnqkFn"
      },
      "source": [
        "- (c) Tracer sur un même graphe l'évolution des précisions d'entraînement et de validation. Que remarquez-vous?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO9ygXrmiHgI"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiMhbtA-mG5-"
      },
      "source": [
        "# <a name=\"train_size\"></a> IV - Influence du nombre d'images dans le jeu d'entraînement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kvNJ8ySr1AK"
      },
      "source": [
        "- (a) Définir une liste ```train_sizes``` contenant les valeurs ```[10, 200, 1000, 5000, 15000, 60000]```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-Ysm0C1iLHr"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpmk11I_uKBl"
      },
      "source": [
        "- (b) Pour chaque élément n de ```train_sizes```, créer un échantillon de taille n de ```X_train``` et de ```y_train```. Stocker ces échantillons dans des listes ```X_train_samples``` et ```y_train_samples```.\n",
        ">  - Attention à ce que les éléments sélectionnés soient les mêmes pour les échantillons de ```X_train``` et ```y_train```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQqxU5nDiMFq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtUlE1-mxCF_"
      },
      "source": [
        "- (c) Pour chaque jeu d'entraînement, définir et entraîner le modèle que dans les parties précédentes grâce à la méthode ```fit``` :\n",
        ">  - L'entraînement devra se faire sur 10 epochs (paramètre ```epochs```).\n",
        ">  \n",
        ">  - Les batchs devront avoir une taille de 20 (paramètre ```batch_size```)\n",
        ">\n",
        ">  - La perfomance du modèle devra être évaluée sur un échantillon de validation contenant 20% des données (paramètre ```validation_split```).\n",
        ">\n",
        ">  - La sortie des entraînements devra être stockée dans une liste nommée ```training_histories```.\n",
        "  \n",
        "- (d) Stocker dans une liste ```times``` la durée de chaque entraînement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz6RyWeciNBD"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiTc9MMJx0Mi"
      },
      "source": [
        "- (e) Tracer sur un même graphe l'évolution de la précision d'entraînement en fonction des epochs pour chaque jeu d'entraînement.\n",
        "\n",
        "- (f) Sur un deuxième graphe, tracer l'évolution de la précision de validation en fonction des epochs pour chaque jeu d'entraînement.\n",
        "\n",
        "- (g) Sur un dernier graphe, tracer le temps d'entraînement du modèle pour chaque jeu d'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKbDiH9siOMP"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb-ObwSwiu_G"
      },
      "source": [
        "# <a name=\"architecture\"></a> V - Influence de l'architecture du réseau de neurones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UtR_OVSp4Rs"
      },
      "source": [
        "## <a name=\"dense\"></a> A - Architecture très basique VS architecture plus complexe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As-P23AWmeeM"
      },
      "source": [
        "Nous allons maintenant évaluer l'influence de l'architecture d'un modèle sur ses performances.\n",
        "- (a) Exécuter la cellule suivante pour instancier le modèle très simple que nous avons utilisé dans les parties précédentes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su9npxs6iPT1"
      },
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Dense(units = 20, input_dim = num_pixels, kernel_initializer ='normal', activation ='tanh'))             \n",
        "model1.add(Dense(units = num_classes, kernel_initializer ='normal', activation ='softmax'))\n",
        "\n",
        "model1.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiJ7EcWynYbr"
      },
      "source": [
        "- (b) Instancier un modèle appelé ```model2``` avec au moins trois couches denses (en comptant la couche finale). Vous êtes libres de choisir les paramètres des couches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JccfufZRiQNC"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg5a88Tjn-6F"
      },
      "source": [
        "- (c) Entraîner les modèles grâce à la méthode ```fit``` :\n",
        ">  - L'entraînement devra se faire sur 10 epochs (paramètre ```epochs```).\n",
        ">  \n",
        ">  - Les batchs devront avoir une taille de 20 (paramètre ```batch_size```)\n",
        ">\n",
        ">  - La perfomance du modèle devra être évaluée sur un échantillon de validation contenant 20% des données (paramètre ```validation_split```).\n",
        ">\n",
        ">  - La sortie des entraînements devra être stockée dans des variables appelées ```training_history_1``` et ```training_history_2```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGfpZp9JiRHm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRcSI0XXogWq"
      },
      "source": [
        "- (d) Tracer sur un même graphe l'évolution de la précision d'entraînement en fonction des epochs pour les deux modèles.\n",
        "\n",
        "- (e) Sur un deuxième graphe, tracer l'évolution de la précision de validation en fonction des epochs pour les deux modèles.\n",
        "\n",
        "Que constatez-vous?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Wa4NqBAiSiy"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ujuPijbi2Ho"
      },
      "source": [
        "## <a name=\"CNN\"></a> B - Introduction aux réseaux de neurones convolutionnels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyJbmG8spTLP"
      },
      "source": [
        "Les couches denses ne sont pas les seules couches que l'on peut créer sur python. Par exemple, on peut définir le réseau de convolution suivant (architecture **LeNet**), qui est bien plus adapté au traitement des images que les modèles définis précédemment.\n",
        "- (f) Exécuter les cellules suivantes pour constater l'efficacité de l'architecture **LeNet**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEoB5q_0iTyO"
      },
      "source": [
        "X_train_conv = X_train.reshape((-1, 28, 28, 1))\n",
        "X_test_conv = X_test.reshape((-1, 28, 28, 1))\n",
        "\n",
        "model_conv = Sequential()\n",
        "model_conv.add(Conv2D(filters=30, kernel_size=(5,5), padding='valid', input_shape=(28,28,1), activation='relu'))\n",
        "model_conv.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_conv.add(Conv2D(filters=16, kernel_size=(3,3), padding='valid', activation='relu'))\n",
        "model_conv.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_conv.add(Dropout(rate=0.2))\n",
        "model_conv.add(Flatten())\n",
        "model_conv.add(Dense(units = 128, activation ='relu'))             \n",
        "model_conv.add(Dense(units = num_classes, activation ='softmax'))\n",
        "\n",
        "model_conv.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIvucXOoiZtP"
      },
      "source": [
        "training_history_conv = model_conv.fit(X_train_conv, y_train, epochs = 10, batch_size = 20, validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHumQ3yLibUb"
      },
      "source": [
        "plt.figure(figsize=(24,8))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(np.arange(1 , 11, 1), training_history_1.history['accuracy'], label = 'model1', color='blue')\n",
        "plt.plot(np.arange(1 , 11, 1), training_history_2.history['accuracy'], label = 'model2', color='red')\n",
        "plt.plot(np.arange(1 , 11, 1), training_history_conv.history['accuracy'], label = 'model_conv', color='green')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title('Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(np.arange(1 , 11, 1), training_history_1.history['val_accuracy'], label = 'model1', color='blue')\n",
        "plt.plot(np.arange(1 , 11, 1), training_history_2.history['val_accuracy'], label = 'model2', color='red')\n",
        "plt.plot(np.arange(1 , 11, 1), training_history_conv.history['val_accuracy'], label = 'model_conv', color='green')\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}